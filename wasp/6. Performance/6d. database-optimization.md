# Database Optimization Guide

## Overview
This guide organizes our existing database optimization documentation into a structured workflow.

## Quick Reference
- [Optimization Basics](6a.%20optimization-basics.md)
- [Frontend Optimization](6b.%20frontend-optimization.md)
- [Backend Optimization](6c.%20backend-optimization.md)

## Query Optimization

### 1. Index Management
From our index optimization:
```sql
-- SQL index optimization examples
-- Create composite index for frequent queries
CREATE INDEX idx_tasks_user_status ON tasks(user_id, status);

-- Create partial index for specific conditions
CREATE INDEX idx_tasks_active ON tasks(created_at)
WHERE status = 'active';

-- Create index for full-text search
CREATE INDEX idx_tasks_description_gin ON tasks
USING gin(to_tsvector('english', description));
```

### 2. Query Analysis
Reference our query analysis:
```javascript
// services/queryAnalyzer.js
class QueryAnalyzer {
  async analyzeQuery(query) {
    const explain = await prisma.$queryRaw`
      EXPLAIN ANALYZE ${query}
    `
    
    return {
      executionTime: this.extractExecutionTime(explain),
      scanType: this.extractScanType(explain),
      indexUsage: this.checkIndexUsage(explain)
    }
  }
  
  optimizeQuery(analysis) {
    const recommendations = []
    
    if (analysis.scanType === 'Seq Scan' && analysis.executionTime > 100) {
      recommendations.push('Consider adding an index')
    }
    
    if (!analysis.indexUsage && analysis.executionTime > 50) {
      recommendations.push('Existing indexes are not being used')
    }
    
    return recommendations
  }
}
```

## Database Design

### 1. Schema Optimization
From our schema optimization:
```javascript
// prisma/schema.prisma
model User {
  id        Int      @id @default(autoincrement())
  email     String   @unique
  name      String?
  tasks     Task[]
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  @@index([email])
  @@map("users")
}

model Task {
  id          Int      @id @default(autoincrement())
  title       String
  status      String
  priority    Int
  userId      Int
  user        User     @relation(fields: [userId], references: [id])
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt

  @@index([userId, status])
  @@index([priority, status])
  @@map("tasks")
}
```

### 2. Relationship Management
```javascript
// services/dataLoader.js
const DataLoader = require('dataloader')

class TaskLoader {
  constructor(prisma) {
    this.prisma = prisma
    
    this.userLoader = new DataLoader(async (userIds) => {
      const users = await prisma.user.findMany({
        where: {
          id: { in: userIds }
        }
      })
      
      return userIds.map(id => 
        users.find(user => user.id === id)
      )
    })
    
    this.taskLoader = new DataLoader(async (taskIds) => {
      const tasks = await prisma.task.findMany({
        where: {
          id: { in: taskIds }
        },
        include: {
          user: true
        }
      })
      
      return taskIds.map(id =>
        tasks.find(task => task.id === id)
      )
    })
  }
}
```

## Connection Management

### 1. Connection Pool
From our connection pool setup:
```javascript
// database/pool.js
const { Pool } = require('pg')

const pool = new Pool({
  user: process.env.DB_USER,
  host: process.env.DB_HOST,
  database: process.env.DB_NAME,
  password: process.env.DB_PASSWORD,
  port: process.env.DB_PORT,
  max: 20, // Maximum number of clients
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
  maxUses: 7500 // Maximum number of uses before client is destroyed
})

pool.on('error', (err, client) => {
  console.error('Unexpected error on idle client', err)
})

async function query(text, params) {
  const start = Date.now()
  const res = await pool.query(text, params)
  const duration = Date.now() - start
  
  console.log('executed query', {
    text,
    duration,
    rows: res.rowCount
  })
  
  return res
}
```

### 2. Transaction Management
```javascript
// services/transaction.js
class TransactionManager {
  constructor(prisma) {
    this.prisma = prisma
  }
  
  async withTransaction(callback) {
    try {
      return await this.prisma.$transaction(async (tx) => {
        return await callback(tx)
      }, {
        isolationLevel: Prisma.TransactionIsolationLevel.Serializable,
        maxWait: 5000,
        timeout: 10000
      })
    } catch (error) {
      console.error('Transaction failed:', error)
      throw error
    }
  }
  
  async batchOperation(items, operation) {
    const batchSize = 100
    const results = []
    
    for (let i = 0; i < items.length; i += batchSize) {
      const batch = items.slice(i, i + batchSize)
      const batchResults = await this.withTransaction(async (tx) => {
        return Promise.all(
          batch.map(item => operation(item, tx))
        )
      })
      results.push(...batchResults)
    }
    
    return results
  }
}
```

## Data Migration

### 1. Migration Strategy
From our migration patterns:
```javascript
// migrations/20240101000000_add_task_priority.js
async function up(prisma) {
  // Create temporary table
  await prisma.$executeRaw`
    CREATE TABLE temp_tasks AS
    SELECT * FROM tasks
  `
  
  // Add new column
  await prisma.$executeRaw`
    ALTER TABLE tasks
    ADD COLUMN priority INTEGER DEFAULT 0
  `
  
  // Update data in batches
  const batchSize = 1000
  let processed = 0
  
  while (true) {
    const batch = await prisma.$executeRaw`
      UPDATE tasks
      SET priority = CASE
        WHEN status = 'urgent' THEN 3
        WHEN status = 'high' THEN 2
        ELSE 1
      END
      WHERE id IN (
        SELECT id FROM tasks
        ORDER BY id
        LIMIT ${batchSize}
        OFFSET ${processed}
      )
    `
    
    if (batch === 0) break
    processed += batchSize
  }
}
```

### 2. Data Archival
```javascript
// services/archival.js
class DataArchival {
  constructor(prisma) {
    this.prisma = prisma
  }
  
  async archiveOldRecords(options) {
    const {
      table,
      condition,
      batchSize = 1000,
      archiveTable
    } = options
    
    let archived = 0
    
    while (true) {
      const records = await this.prisma[table].findMany({
        where: condition,
        take: batchSize
      })
      
      if (records.length === 0) break
      
      await this.prisma.$transaction([
        // Copy to archive
        this.prisma[archiveTable].createMany({
          data: records
        }),
        // Delete original
        this.prisma[table].deleteMany({
          where: {
            id: {
              in: records.map(r => r.id)
            }
          }
        })
      ])
      
      archived += records.length
    }
    
    return archived
  }
}
```

## Performance Monitoring

### 1. Query Monitoring
From our monitoring setup:
```javascript
// monitoring/database.js
const prometheus = require('prom-client')

const queryDuration = new prometheus.Histogram({
  name: 'db_query_duration_seconds',
  help: 'Duration of database queries in seconds',
  labelNames: ['query', 'table']
})

const connectionPoolMetrics = new prometheus.Gauge({
  name: 'db_connection_pool_size',
  help: 'Number of connections in the pool',
  labelNames: ['state']
})

const queryErrors = new prometheus.Counter({
  name: 'db_query_errors_total',
  help: 'Total number of database query errors',
  labelNames: ['type']
})
```

### 2. Performance Analysis
```javascript
// monitoring/analyzer.js
class DatabaseAnalyzer {
  async analyzePerformance() {
    const metrics = await this.collectMetrics()
    return this.generateRecommendations(metrics)
  }
  
  async collectMetrics() {
    return {
      slowQueries: await this.findSlowQueries(),
      tableStats: await this.getTableStats(),
      indexUsage: await this.getIndexUsage(),
      connectionStats: await this.getConnectionStats()
    }
  }
  
  generateRecommendations(metrics) {
    const recommendations = []
    
    if (metrics.slowQueries.length > 0) {
      recommendations.push({
        type: 'QUERY_OPTIMIZATION',
        queries: metrics.slowQueries,
        suggestion: 'Consider adding indexes or optimizing these queries'
      })
    }
    
    if (metrics.indexUsage.unusedIndexes.length > 0) {
      recommendations.push({
        type: 'INDEX_CLEANUP',
        indexes: metrics.indexUsage.unusedIndexes,
        suggestion: 'Consider removing unused indexes'
      })
    }
    
    return recommendations
  }
}
```

## Database Checklist

### Query Optimization
- [ ] Index analysis
- [ ] Query performance
- [ ] Join optimization
- [ ] Pagination setup
- [ ] Cache strategy

### Schema Design
- [ ] Normalization
- [ ] Indexing strategy
- [ ] Constraints
- [ ] Partitioning
- [ ] Archival strategy

### Connection Management
- [ ] Pool configuration
- [ ] Transaction handling
- [ ] Error handling
- [ ] Retry strategy
- [ ] Monitoring setup

## Next Steps
1. Implement [Backend Optimization](6c.%20backend-optimization.md)
2. Set up [Monitoring](../7.%20Deployment/7d.%20monitoring-setup.md)
3. Configure [Security](../5.%20Security/5a.%20security-basics.md)

## Related Documentation
- [Performance Guide](6a.%20optimization-basics.md)
- [Backend Guide](6c.%20backend-optimization.md)
- [Monitoring Guide](../7.%20Deployment/7d.%20monitoring-setup.md)
